{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf2e748c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.stats as scs\n",
    "import random\n",
    "import math\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd1403e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2afbe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/AdSmartABdata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d0ae644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(df):\n",
    "  '''\n",
    "  segment data into exposed and control groups\n",
    "  consider that SmartAd runs the experment hourly, group data into hours. \n",
    "      Hint: create new column to hold date+hour and use df.column.map(lambda x:  pd.Timestamp(x,tz=None).strftime('%Y-%m-%d:%H'))\n",
    "  create two dataframes with bernouli series 1 for posetive(yes) and 0 for negative(no)\n",
    "    Hint: Given engagement(sum of yes and no until current observation as an array) and success (yes countas an array), the method generates random binomial distribution\n",
    "        #Example\n",
    "           engagement = np.array([5, 3, 3])\n",
    "           yes = np.array([2, 0, 3])       \n",
    "         Output is \"[1] 1 0 1 0 0 0 0 0 1 1 1\", showing a binary array of 5+3+3 values\n",
    "         of which 2 of the first 5 are ones, 0 of the next 3 are ones, and all 3 of\n",
    "         the last 3 are ones where position the ones is randomly distributed within each group.\n",
    "  '''\n",
    "  \n",
    "  # Filter out users that were not interacting\n",
    "  relevant_rows = df.query('yes == 1 | no == 1')\n",
    "  \n",
    "  # Get exposed and control groups \n",
    "  exposed = relevant_rows[relevant_rows['experiment'] == 'exposed']\n",
    "  control = relevant_rows[relevant_rows['experiment'] == 'control']\n",
    "\n",
    "  # Append hour to date for exposed group\n",
    "  exposed['hour'] = exposed['hour'].astype('str')\n",
    "  exposed['date_hour'] = pd.to_datetime( exposed['date'] + \" \" + exposed['hour'] + \":00\" + \":00\")\n",
    "  exposed['date_hour'] = exposed['date_hour'].map( lambda x:  pd.Timestamp(x, tz=None).strftime('%Y-%m-%d:%H'))\n",
    "\n",
    "  # Append hour to date for control group\n",
    "  control['hour'] = control['hour'].astype('str')\n",
    "  control['date_hour'] = pd.to_datetime(control['date'] + \" \" + control['hour'] + \":00\" + \":00\")\n",
    "  control['date_hour'] = control['date_hour'].map(lambda x:  pd.Timestamp(x, tz=None).strftime('%Y-%m-%d:%H'))\n",
    "\n",
    "\n",
    "  #create two dataframes with bernouli series 1 for posetive(yes) and 0 for negative(no)\n",
    "  #   exposed_bernouli = exposed.groupby(['date_hour'])['yes'].apply(lambda x: np.random.binomial(x, 0.5))\n",
    "  #   control_bernouli = control.groupby(['date_hour'])['yes'].apply(lambda x: np.random.binomial(x, 0.5))  \n",
    "\n",
    "  \n",
    "  #   exposed['engagement_yes'] = exposed.yes.map(lambda x: np.random.binomial(x, 0.5))\n",
    "  #   control['engagement_no'] = exposed.no.map(lambda x: np.random.binomial(x, 0.5))\n",
    "    \n",
    "  \n",
    "  exposed['engagement'] = exposed['yes'] + exposed['no']\n",
    "  control['engagement'] = control['yes'] + control['no']\n",
    "\n",
    "  exposed['success'] = exposed['yes'] \n",
    "  control['success'] = control['yes'] \n",
    "\n",
    "  expo_p = sum(exposed['success']) / sum(exposed['engagement'])\n",
    "  cont_p = sum(control['success']) / sum(control['engagement'])\n",
    "\n",
    "  exposed_engagement = exposed['engagement'].to_numpy()\n",
    "  control_engagement = control['engagement'].to_numpy()\n",
    "\n",
    "  exposed = np.random.choice([0, 1], size=((np.sum(exposed_engagement)),), p=[expo_p, 1-expo_p])\n",
    "  control = np.random.choice([0, 1], size=((np.sum(control_engagement)),), p=[cont_p , 1-cont_p ])\n",
    "    \n",
    "  return exposed, control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9ff326f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "657 586\n"
     ]
    }
   ],
   "source": [
    "control, exposed = transform_data(df)\n",
    "print(len(control), len(exposed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1ca1c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical Columns: ['hour', 'platform_os', 'yes', 'no']\n",
      "Categorical Columns: ['auction_id', 'experiment', 'date', 'device_make', 'browser']\n"
     ]
    }
   ],
   "source": [
    "#checking numerical and categorical data\n",
    "numerical_column = df.select_dtypes(exclude=\"object\").columns.tolist()\n",
    "categorical_column = df.select_dtypes(include=\"object\").columns.tolist()\n",
    "print(\"Numerical Columns:\", numerical_column)\n",
    "print(\"Categorical Columns:\", categorical_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "335a4266",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_group = df.groupby(['experiment'])\n",
    "control = user_group.get_group('control')\n",
    "exposed = user_group.get_group('exposed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "593384c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConditionalSPRT:\n",
    "     \n",
    "    def __init__(self, x, y, odd_ratio, alpha=0.05, beta=0.10, stop=None):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.odd_ratio = odd_ratio\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.stop = stop\n",
    "   \n",
    "    def run(self):\n",
    "        res = conditionalSPRT(self.x, self.y, self.odd_ratio,\n",
    "                              self.alpha, self.beta,\n",
    "                              self.stop)\n",
    "        return res\n",
    "    def resJson(self, res):\n",
    "        outcome,n, k,l,u,truncated,truncate_decision,x1,r,stats,limits = res\n",
    "        jsonRes = {\n",
    "            \"name\": \"Sequential AB testing\",\n",
    "            \"outcome\": outcome,\n",
    "            \"decsionMadeIndex\": k,\n",
    "            \"numberOfObservation\": len(n),\n",
    "            \"truncated\": truncated,\n",
    "            \"truncateDecision\": truncate_decision,        \n",
    "      \n",
    "        }\n",
    "        return jsonRes\n",
    "    \n",
    "    def plotExperiment(self, res):\n",
    "        outcome,n, k,l,u,truncated,truncate_decision,x1,r,stats,limits = res\n",
    "        lower = limits[:, 0]\n",
    "        upper = limits[:,1]\n",
    "\n",
    "        fig, ax = plt.subplots(figsize=(12,7))\n",
    "\n",
    "        ax.plot(n, x1, label='Cumlative value of yes+no')\n",
    "\n",
    "        ax.plot(n, lower, label='Lower Bound', linestyle='--')\n",
    "        ax.plot(n, upper, label='Upper Bound', linestyle='--')\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb448bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conditionalSPRT(x,y,t1,alpha=0.05,beta=0.10,stop=None):\n",
    "    \"\"\"\n",
    "    #\n",
    "    # Meeker's SPRT for matched `x` (treatment) and `y` (control), \n",
    "    # both indicator responses, likelihood ratio t1, error rates alpha and beta,\n",
    "    # and (optionally) truncation after trial stop.\n",
    "    #\n",
    "    # The return variable contains these elements:\n",
    "    #(outcome,n, k,l,u,truncated,truncate_decision,x1,r,stats,limits)\n",
    "    # * outcome:   \"continue,\" \"reject null,\" or \"accept null\".\n",
    "    # * n: number observation used for the decsion\n",
    "    # * k:     Index at which the outcome decision was made (or NA)\n",
    "    # * l:     lower critical point\n",
    "    # * u:     upper critical point\n",
    "    # * truncate_decision: The approximate decision made after truncate point\n",
    "    # * truncated: If the test was truncated, the value of `n.0`; NA otherwise\n",
    "    # * x1:       Original data `x`, cumulative\n",
    "    # * r:         Cumulative sum of x+y\n",
    "    # * stats:     Series of cumulative sums of log probability ratios\n",
    "    # * limits:    Two rows giving lower and upper critical limits, respectively\n",
    "    #\n",
    "    \"\"\"\n",
    "    \n",
    "    if t1<=1:\n",
    "        print('warning',\"Odd ratio should exceed 1.\")\n",
    "    if (alpha >0.5) | (beta >0.5):\n",
    "        print('warning',\"Unrealistic values of alpha or beta were passed.\"\n",
    "                 +\" You should have good reason to use large alpha & beta values\")\n",
    "    if stop!=None:\n",
    "        stop=math.floor(n0)\n",
    "\n",
    "    def comb(n, k):\n",
    "        return math.factorial(n) // math.factorial(k) // math.factorial(n - k)\n",
    "\n",
    "    def lchoose(b, j):\n",
    "        a=[]\n",
    "        if (type(j) is list) | (isinstance(j,np.ndarray)==True):\n",
    "            if len(j)<2:\n",
    "                j=j[0]\n",
    "        if (type(j) is list) | (isinstance(j,np.ndarray)==True):\n",
    "            for k in j:\n",
    "                n=b\n",
    "                if (0 <= k) & (k<= n):\n",
    "                    a.append(math.log(comb(n,k)))\n",
    "                else:\n",
    "                    a.append(0)\n",
    "        else:\n",
    "            n=b\n",
    "            k=j\n",
    "            if (0 <= k) & (k<= n):\n",
    "                a.append(math.log(comb(n,k)))\n",
    "            else:\n",
    "                a.append(0)\n",
    "\n",
    "        return np.array(a)\n",
    "\n",
    "    def g(x,r,n,t1,t0=1):\n",
    "        return -math.log(h(x,r,n,t1))+math.log(h(x,r,n,t0))\n",
    "\n",
    "    def h(x,r,n,t=1):\n",
    "     \n",
    "        return f(r,n,t,offset=ftermlog(x,r,n,t))\n",
    "\n",
    "    def f(r,n,t,offset=0):\n",
    "        upper=max(0,r-n)\n",
    "        lower=min(n,r)\n",
    "        rng=list(range(upper,lower+1))\n",
    "        return np.sum(fterm(rng,r,n,t,offset))\n",
    "\n",
    "    def fterm(j,r,n,t,offset=0):\n",
    "        ftlog=ftermlog(j,r,n,t,offset)\n",
    "        return np.array([math.exp(ex) for ex in ftlog])\n",
    "\n",
    "    def ftermlog(j,r,n,t,offset=0):\n",
    "    \n",
    "        xx=r-j\n",
    "        lch=lchoose(n,j)\n",
    "        lchdiff=lchoose(n,xx)\n",
    "        lg=np.array(j)*math.log(t)\n",
    "        lgsum=lch+lchdiff\n",
    "        lgsum2=lgsum+lg\n",
    "        lgdiff=lgsum2-offset\n",
    "\n",
    "        return lgdiff\n",
    "\n",
    "    def logf(r,n,t,offset=0):\n",
    "     \n",
    "        z=f(r,n,t,offset)\n",
    "        if z>0:\n",
    "            return math.log(z)\n",
    "        else:\n",
    "            return np.nan\n",
    "\n",
    "    def clowerUpper(r,n,t1c,t0=1,alpha=0.05,beta=0.10):\n",
    "     \n",
    "        offset=ftermlog(math.ceil(r/2),r,n,t1c)\n",
    "        z=logf(r,n,t1c,logf(r,n,t0,offset)+offset)\n",
    "        a=-math.log(alpha/(1-beta))\n",
    "        b=math.log(beta/(1-alpha))\n",
    "        lower=b\n",
    "        upper=1+a\n",
    "        return (np.array([lower,upper])+z)/math.log(t1c/t0)\n",
    "\n",
    "    l=math.log(beta/(1-alpha))\n",
    "    u=-math.log(alpha/(1-beta))\n",
    "    sample_size=min(len(x),len(y))\n",
    "    n=np.array(range(1,sample_size+1))\n",
    "\n",
    "    if stop!=None:\n",
    "        n=np.array([z for z in n if z<=stop])\n",
    "    x1=np.cumsum(x[n-1])\n",
    "    r=x1+np.cumsum(y[n-1])\n",
    "    stats=np.array(list(map(g,x1, r, n, [t1]*len(x1)))) #recurcively calls g\n",
    "     #\n",
    "      # Perform the test by finding the first index, if any, at which `stats`\n",
    "      # falls outside the open interval (l, u).\n",
    "      #\n",
    "    clu=list(map(clowerUpper,r,n,[t1]*len(r),[1]*len(r),[alpha]*len(r), [beta]*len(r)))\n",
    "    limits=[]\n",
    "    for v in clu:\n",
    "        inArray=[]\n",
    "        for vin in v:\n",
    "            inArray.append(math.floor(vin))\n",
    "        limits.append(np.array(inArray))\n",
    "    limits=np.array(limits)\n",
    "\n",
    "    k=np.where((stats>=u) | (stats<=l))\n",
    "    cvalues=stats[k]\n",
    "    if cvalues.shape[0]<1:\n",
    "        k= np.nan\n",
    "        outcome='Unable to conclude.Needs more sample.'\n",
    "    else:\n",
    "        k=np.min(k)\n",
    "        if stats[k]>=u:\n",
    "            outcome=f'Exposed group produced a statistically significant increase.'\n",
    "        else:\n",
    "            outcome='Their is no statistically significant difference between two test groups'\n",
    "    if (stop!=None) & (k==np.nan):\n",
    "      #\n",
    "      # Truncate at trial stop, using Meeker's H0-conservative formula (2.2).\n",
    "      # Leave k=NA to indicate the decision was made due to truncation.\n",
    "      #\n",
    "        c1=clowerUpper(r,stop,t1,alpha,beta)\n",
    "        c1=math.floor(np.mean(c1)-0.5)\n",
    "        if x1[n0]<=c1:\n",
    "            truncate_decision='h0'\n",
    "            outcome='Maximum Limit Decision. The aproximate decision point shows their is no statistically significant difference between two test groups'\n",
    "        else:\n",
    "            truncate_decision='h1'\n",
    "            outcome=f'Maximum Limit Decision. The aproximate decision point shows exposed group produced a statistically significant increase.'\n",
    "        truncated=stop\n",
    "    else:\n",
    "        truncate_decision='Non'\n",
    "        truncated=np.nan\n",
    "    return (outcome,n, k,l,u,truncated,truncate_decision,x1,r,stats,limits)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
